"""
RAG (Retrieval-Augmented Generation) Flask åº”ç”¨
ä½¿ç”¨ LangChain + FAISS + OpenAI å®ç°é—®ç­”ç³»ç»Ÿ
"""
import os
from flask import Flask, request, jsonify
from langchain_community.vectorstores import FAISS
from langchain.embeddings import OpenAIEmbeddings
from langchain.llms import OpenAI
from langchain.chains import RetrievalQA
from langchain.prompts import PromptTemplate
from langchain.text_splitter import CharacterTextSplitter
from langchain_community.document_loaders import TextLoader

app = Flask(__name__)

# é…ç½®
OPENAI_API_KEY = os.getenv("OPENAI_API_KEY")
FAISS_INDEX_PATH = "faiss_index"

# åˆå§‹åŒ–å…¨å±€å˜é‡
qa_chain = None
_initialized = False


def initialize_qa_chain():
    """åˆå§‹åŒ– QA é“¾"""
    global qa_chain
    
    try:
        # åˆå§‹åŒ– OpenAI Embeddings
        embeddings = OpenAIEmbeddings(
            openai_api_key=OPENAI_API_KEY
        )
        
        # åŠ è½½ FAISS å‘é‡æ•°æ®åº“
        vectorstore = FAISS.load_local(
            FAISS_INDEX_PATH,
            embeddings,
            allow_dangerous_deserialization=True
        )
        
        # åˆå§‹åŒ– LLM
        llm = OpenAI(
            temperature=0.7,
            openai_api_key=OPENAI_API_KEY
        )
        
        # åˆ›å»ºè‡ªå®šä¹‰ prompt
        prompt_template = """ä½¿ç”¨ä»¥ä¸‹ä¸Šä¸‹æ–‡æ¥å›ç­”é—®é¢˜ã€‚å¦‚æœä½ ä¸çŸ¥é“ç­”æ¡ˆï¼Œå°±è¯´ä¸çŸ¥é“ï¼Œä¸è¦è¯•å›¾ç¼–é€ ç­”æ¡ˆã€‚

ä¸Šä¸‹æ–‡: {context}

é—®é¢˜: {question}

è¯¦ç»†å›ç­”:"""
        
        PROMPT = PromptTemplate(
            template=prompt_template,
            input_variables=["context", "question"]
        )
        
        # åˆ›å»º QA é“¾
        qa_chain = RetrievalQA.from_chain_type(
            llm=llm,
            chain_type="stuff",
            retriever=vectorstore.as_retriever(search_kwargs={"k": 3}),
            return_source_documents=True,
            chain_type_kwargs={"prompt": PROMPT}
        )
        
        print("âœ… QA Chain åˆå§‹åŒ–æˆåŠŸï¼")
        
    except Exception as e:
        print(f"âŒ åˆå§‹åŒ– QA Chain å¤±è´¥: {str(e)}")
        raise


@app.route('/')
def home():
    """å¥åº·æ£€æŸ¥ç«¯ç‚¹"""
    return jsonify({
        "status": "healthy",
        "message": "RAG é—®ç­”ç³»ç»Ÿæ­£åœ¨è¿è¡Œ",
        "version": "1.0.0"
    })


@app.route('/health')
def health():
    """å¥åº·æ£€æŸ¥ç«¯ç‚¹"""
    return jsonify({"status": "ok"})


@app.route('/status')
def status():
    """ç³»ç»ŸçŠ¶æ€æ£€æŸ¥ç«¯ç‚¹"""
    return jsonify({
        "initialized": _initialized,
        "qa_chain_ready": qa_chain is not None,
        "openai_api_key_set": OPENAI_API_KEY is not None and OPENAI_API_KEY != "",
        "faiss_index_exists": os.path.exists(FAISS_INDEX_PATH),
        "data_file_exists": os.path.exists("data.txt")
    })


@app.route('/ask', methods=['POST'])
def ask():
    """é—®ç­”ç«¯ç‚¹"""
    try:
        # ç¡®ä¿ç³»ç»Ÿå·²åˆå§‹åŒ–
        ensure_initialized()
        
        # æ£€æŸ¥ QA chain æ˜¯å¦åˆå§‹åŒ–
        if qa_chain is None:
            return jsonify({
                "error": "QA ç³»ç»Ÿæœªåˆå§‹åŒ–",
                "message": "çŸ¥è¯†åº“åˆå§‹åŒ–å¤±è´¥ï¼Œè¯·æ£€æŸ¥é…ç½®",
                "suggestion": "è¯·ç¡®ä¿ OPENAI_API_KEY å·²æ­£ç¡®é…ç½®"
            }), 503
        
        # è·å–é—®é¢˜
        data = request.get_json()
        if not data or 'question' not in data:
            return jsonify({
                "error": "è¯·æä¾› 'question' å­—æ®µ"
            }), 400
        
        question = data['question']
        
        if not question.strip():
            return jsonify({
                "error": "é—®é¢˜ä¸èƒ½ä¸ºç©º"
            }), 400
        
        # æ‰§è¡Œé—®ç­”
        result = qa_chain({"query": question})
        
        # æå–æºæ–‡æ¡£
        sources = []
        if 'source_documents' in result:
            sources = [
                {
                    "content": doc.page_content[:200] + "...",
                    "metadata": doc.metadata
                }
                for doc in result['source_documents']
            ]
        
        return jsonify({
            "question": question,
            "answer": result['result'],
            "sources": sources
        })
    
    except Exception as e:
        return jsonify({
            "error": f"å¤„ç†é—®é¢˜æ—¶å‡ºé”™: {str(e)}"
        }), 500


@app.route('/info')
def info():
    """ç³»ç»Ÿä¿¡æ¯ç«¯ç‚¹"""
    return jsonify({
        "app": "RAG é—®ç­”ç³»ç»Ÿ",
        "description": "åŸºäº LangChain + FAISS + OpenAI çš„æ£€ç´¢å¢å¼ºç”Ÿæˆç³»ç»Ÿ",
        "endpoints": {
            "/": "å¥åº·æ£€æŸ¥",
            "/health": "å¥åº·çŠ¶æ€",
            "/ask": "é—®ç­”æ¥å£ (POST)",
            "/info": "ç³»ç»Ÿä¿¡æ¯"
        },
        "usage": {
            "method": "POST",
            "endpoint": "/ask",
            "body": {
                "question": "ä½ çš„é—®é¢˜"
            }
        }
    })


def ensure_initialized():
    """ç¡®ä¿ç³»ç»Ÿå·²åˆå§‹åŒ–ï¼ˆåªæ‰§è¡Œä¸€æ¬¡ï¼‰"""
    global _initialized
    if _initialized:
        return
    
    print("ğŸš€ æ­£åœ¨åˆå§‹åŒ– RAG é—®ç­”ç³»ç»Ÿ...")
    
    if not OPENAI_API_KEY:
        print("âš ï¸ è­¦å‘Š: æœªè®¾ç½® OPENAI_API_KEY ç¯å¢ƒå˜é‡")
        _initialized = True
        return
    
    # åˆ›å»ºç´¢å¼•
    create_sample_index_if_needed()
    
    # åˆå§‹åŒ– QA chain
    if os.path.exists(FAISS_INDEX_PATH):
        initialize_qa_chain()
    
    _initialized = True
    print("âœ… RAG é—®ç­”ç³»ç»Ÿåˆå§‹åŒ–å®Œæˆ")


def create_sample_index_if_needed():
    """å¦‚æœç´¢å¼•ä¸å­˜åœ¨ï¼Œåˆ›å»ºä¸€ä¸ªç¤ºä¾‹ç´¢å¼•"""
    if os.path.exists(FAISS_INDEX_PATH):
        return
    
    try:
        print("ğŸ“ FAISS ç´¢å¼•ä¸å­˜åœ¨ï¼Œæ­£åœ¨åˆ›å»ºç¤ºä¾‹ç´¢å¼•...")
        
        # æ£€æŸ¥ data.txt æ˜¯å¦å­˜åœ¨
        if not os.path.exists("data.txt"):
            # åˆ›å»ºç¤ºä¾‹æ•°æ®
            sample_data = """äººå·¥æ™ºèƒ½ï¼ˆAIï¼‰æ˜¯è®¡ç®—æœºç§‘å­¦çš„ä¸€ä¸ªåˆ†æ”¯ï¼Œè‡´åŠ›äºåˆ›å»ºèƒ½å¤Ÿæ‰§è¡Œé€šå¸¸éœ€è¦äººç±»æ™ºèƒ½çš„ä»»åŠ¡çš„ç³»ç»Ÿã€‚

æœºå™¨å­¦ä¹ æ˜¯äººå·¥æ™ºèƒ½çš„ä¸€ä¸ªå­é›†ï¼Œå®ƒä½¿è®¡ç®—æœºèƒ½å¤Ÿä»æ•°æ®ä¸­å­¦ä¹ å¹¶æ”¹è¿›ï¼Œè€Œæ— éœ€æ˜ç¡®ç¼–ç¨‹ã€‚

æ·±åº¦å­¦ä¹ æ˜¯æœºå™¨å­¦ä¹ çš„ä¸€ä¸ªå­é›†ï¼Œä½¿ç”¨ç¥ç»ç½‘ç»œæ¥æ¨¡æ‹Ÿäººè„‘çš„å·¥ä½œæ–¹å¼ã€‚

è‡ªç„¶è¯­è¨€å¤„ç†ï¼ˆNLPï¼‰æ˜¯äººå·¥æ™ºèƒ½çš„ä¸€ä¸ªé¢†åŸŸï¼Œä¸“æ³¨äºä½¿è®¡ç®—æœºèƒ½å¤Ÿç†è§£ã€è§£é‡Šå’Œç”Ÿæˆäººç±»è¯­è¨€ã€‚

è®¡ç®—æœºè§†è§‰æ˜¯äººå·¥æ™ºèƒ½çš„ä¸€ä¸ªé¢†åŸŸï¼Œä½¿è®¡ç®—æœºèƒ½å¤Ÿä»æ•°å­—å›¾åƒæˆ–è§†é¢‘ä¸­è·å–é«˜çº§ç†è§£ã€‚"""
            
            with open("data.txt", "w", encoding="utf-8") as f:
                f.write(sample_data)
            print("âœ… åˆ›å»ºäº†ç¤ºä¾‹æ•°æ®æ–‡ä»¶ data.txt")
        
        # åŠ è½½æ–‡æ¡£
        loader = TextLoader("data.txt", encoding="utf-8")
        documents = loader.load()
        
        # åˆ†å‰²æ–‡æ¡£
        text_splitter = CharacterTextSplitter(
            chunk_size=500,
            chunk_overlap=50,
            separator="\n\n"
        )
        texts = text_splitter.split_documents(documents)
        
        # åˆ›å»ºå‘é‡å­˜å‚¨
        embeddings = OpenAIEmbeddings(openai_api_key=OPENAI_API_KEY)
        vectorstore = FAISS.from_documents(texts, embeddings)
        
        # ä¿å­˜ç´¢å¼•
        vectorstore.save_local(FAISS_INDEX_PATH)
        print(f"âœ… FAISS ç´¢å¼•å·²åˆ›å»ºå¹¶ä¿å­˜åˆ° {FAISS_INDEX_PATH}")
        
    except Exception as e:
        print(f"âŒ åˆ›å»º FAISS ç´¢å¼•å¤±è´¥: {str(e)}")


if __name__ == '__main__':
    # å¯åŠ¨æ—¶åˆå§‹åŒ– QA chain
    print("ğŸš€ æ­£åœ¨å¯åŠ¨ RAG é—®ç­”ç³»ç»Ÿ...")
    
    # æ£€æŸ¥ OpenAI API Key
    if not OPENAI_API_KEY:
        print("âš ï¸  è­¦å‘Š: æœªè®¾ç½® OPENAI_API_KEY ç¯å¢ƒå˜é‡")
    else:
        # å¦‚æœç´¢å¼•ä¸å­˜åœ¨ï¼Œåˆ›å»ºå®ƒ
        create_sample_index_if_needed()
        
        # åˆå§‹åŒ– QA chain
        if os.path.exists(FAISS_INDEX_PATH):
            initialize_qa_chain()
        else:
            print(f"âš ï¸  è­¦å‘Š: FAISS ç´¢å¼•ç›®å½•ä¸å­˜åœ¨: {FAISS_INDEX_PATH}")
    
    # å¯åŠ¨ Flask åº”ç”¨
    port = int(os.getenv('PORT', 8080))
    app.run(host='0.0.0.0', port=port, debug=False)

